import numpy
import math, random


class NeuraltNettverk():

    def __init__(self,nh,c,d):
        # Argumenter;  nh = gjemte noder, c= antall klasser, d= feature vektor dimensjon

        # Omraadet vektene skal ligge mellom og antall utganger.
        self.nh = nh
        self.initVekt = 1/math.sqrt(self.nh)
        self.antallKlasser = c
        self.antallInput = d

        # Learning raten til det neurale nettverket (mulighet for aa kunne endre)
        self.larerate = 1

        # Lager utgangsvektor fra den gjemte noden og utgangen
        self.fnetHidden = numpy.zeros((self.nh,1))
        self.fnetUtgang = numpy.zeros((self.antallKlasser,1))

        # DUMMY VEKTOR. MAA ERSTATTES!
        self.target = numpy.array([1,0])
        self.inngangsVektor = numpy.ones((self.antallInput,1))

        # Lager tomme matriser for vektene
        self.vektItH = numpy.empty((self.nh, self.antallInput))
        self.vektHtO = numpy.empty((self.antallKlasser,self.nh))

        # Lager tomme vektorer for ItH, HtO Bias og bias vekt
        self.ItHBias = numpy.ones((self.nh,1))
        self.vektBiasItH = numpy.empty((self.nh,1))
        self.HtOBias = numpy.ones((self.antallKlasser,1))
        self.vektBiasHtO = numpy.empty((self.antallKlasser,1))


    def lageVekter(self):
    # Denne metoden initerer vekter og bias til det neurale nettverket.

        # Fyller inn verdier i nodevekt og bias.
        for rad in range(0, self.nh):

            # Lager biasvekt for Input to Hidden
            self.vektBiasItH[rad,0] = 0.5*math.pow(-1,rad)

            # Lager biasvekt for Hidden to Output
            if rad <= self.antallKlasser-1:
                self.vektBiasHtO[rad,0] = 0.5*math.pow(-1,rad)

            # Lager Input to Hidden nodevekt i omraadet -1/sqrt(nh)<noder<1/sqrt(nh).
            for kol in range(0,self.antallInput):
                self.vektItH[rad, kol] = (random.randrange(-100,100) * self.initVekt)/100

                # Lager Hidden to Output nodevekt i omraadet -1/sqrt(nh)<noder<1/sqrt(nh).
                if kol <= self.antallKlasser-1:
                    self.vektHtO[kol, rad] = (random.randrange(-100,100) * self.initVekt)/100


    def FeedForward(self):
        # Regner ut FeedForward for det neurale nettverket.

        # Finner "net_j" for Input to Hidden
        self.netHidden = (self.vektItH).dot(self.inngangsVektor) + self.ItHBias*self.vektBiasItH

        # Finner utgangen til den gjemte noden. Bruker aktiveringsfunkjson paa formen 1/(1+e^(net))
        for node in range(0,self.nh):
            self.fnetHidden[node,0] = 1/(1 + math.exp((-1)*self.netHidden[node,0]))

        # Finner "net" for Hidden to Output.
        self.netUtgang = (self.vektHtO).dot(self.fnetHidden) + self.HtOBias*self.vektBiasHtO

        # Regner ut utgangsverdiene z. Bruker aktiveringsfunkjson paa formen 1/(1+e^(net))
        for node in range(0,self.antallKlasser):
            self.fnetUtgang[node,0] = 1/(1 + math.exp((-1)*self.netUtgang[node,0]))

        # Returnerer utgangsvektor, der hver element beskrive en klasse.
        return self.fnetUtgang

    def Backward(self):

        # Finner f(net_1) og f(net_2) derivert
        fnetHiddenDerivert = self.fnetHidden.T*(numpy.ones((1,self.nh)) - self.fnetHidden.T)
        fnetUtgangDerivert = self.fnetUtgang.T*(numpy.ones((1,self.antallKlasser)) - self.fnetUtgang.T)

        # Finner sensitiviteten til Hidden to Output og Input to Hidden
        sensitivitetHtO = (((self.target - self.fnetUtgang.T))*fnetUtgangDerivert).T
        sensitivitetItH = fnetHiddenDerivert.T*self.vektHtO.T.dot(sensitivitetHtO)

        # Finner delta vekt HtO og ItH
        deltaVektHtO = sensitivitetHtO.dot(self.fnetHidden.T)
        deltaVektItH = sensitivitetItH.dot(self.inngangsVektor.T)

        # Finner delta vekt bias HtO og ItH
        # SPORRE TRYGVE! Dersom Y0 er satt til 1, saa vil delta vekt bias = sensitiviteten?
        deltaVektBiasHtO = sensitivitetHtO
        deltaVektBiasItH = sensitivitetItH

        # Oppdaterer Input to Hidden vektene
        self.vektItH = self.vektItH + deltaVektItH
        self.vektBiasItH = self.vektBiasItH + deltaVektBiasItH

        # Oppdaterer Hidden to Output vektene
        self.vektHtO = self.HtOBias + deltaVektHtO
        self.vektBiasHtO = self.vektBiasHtO + deltaVektBiasHtO

        return sensitivitetHtO


Program = NeuraltNettverk(10,2,100)
Program.lageVekter()

for iterasjon in range(0,100):
    test = Program.FeedForward()
    Program.Backward()
    print(test)

